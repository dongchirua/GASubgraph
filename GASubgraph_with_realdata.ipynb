{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import os\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Set, Tuple, Union, Callable\n",
    "from typing_extensions import Literal\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import networkx.algorithms.isomorphism as iso\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from easydict import EasyDict as edict\n",
    "from ipywidgets import interact\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from torch import FloatTensor, LongTensor, Tensor\n",
    "from torch_geometric.data import Batch, Data, InMemoryDataset\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, GINConv, GNNExplainer, global_max_pool\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.models import GIN\n",
    "from torch_geometric.utils import k_hop_subgraph, remove_self_loops, to_networkx\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "run GA with dummy classification but on realdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "def setup_logger():\n",
    "    \"\"\"Configure logger.\n",
    "    \"\"\"\n",
    "\n",
    "    logging.basicConfig(\n",
    "        format='%(asctime)s | %(name)s | %(message)s',\n",
    "        level=logging.INFO,\n",
    "        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    return logging.getLogger('GASub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Args:\n",
    "    \"\"\"A class containing arguments used for setting up the dataset and model.\"\"\"\n",
    "    batch_size: int = 32  # Batch size for the training loop.\n",
    "    num_workers: int = 2  # Number of workers to use for the data loader.\n",
    "    learning_rate: float = 0.001  # Learning rate.\n",
    "    weight_decay: float = 5e-4  # Weight decay.\n",
    "    num_epochs: int = 300  # Number of training epochs.\n",
    "    num_layers: int = 3  # Number of message passing layers in the GNN model.\n",
    "    hidden_features: int = 32  # Dimensionality of the hidden layers in the GNN.\n",
    "    dropout: float = 0.2  # Dropout probability.\n",
    "    seed: int = 27  # Random seed.\n",
    "    pre_train: bool = True  # Change to False if want to retrain\n",
    "    CXPB = 0.5\n",
    "    MUTPB =  0.2\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over_write: False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba1100a3f0a432fa2e6ab0f333b813f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5f797a0364409f8dffbf38bfb31dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from vulexp.data_models.pl_data_module import DataModule\n",
    "from vulexp.data_models.reveal_data import Reveal\n",
    "\n",
    "data_dir = 'data/reveal/'\n",
    "reveal_dataset = Reveal(data_dir, to_undirected=True, seed=args.seed)\n",
    "\n",
    "\n",
    "reveal_train, reveal_val, reveal_test = reveal_dataset.generate_train_test()\n",
    "\n",
    "reveal_train_loader = DataLoader(\n",
    "    dataset=reveal_train,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=args.num_workers,\n",
    "    shuffle=True\n",
    ")\n",
    "reveal_valid_loader = DataLoader(\n",
    "    dataset=reveal_val,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=args.num_workers,\n",
    "    shuffle=False\n",
    "    )\n",
    "reveal_test_loader = DataLoader(\n",
    "    dataset=reveal_test,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=args.num_workers,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingModule(\n",
       "  (model): GIN(\n",
       "    (convs): ModuleList(\n",
       "      (0): GINConv(nn=Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      ))\n",
       "      (1): GINConv(nn=Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      ))\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.8, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vulexp.ml_models.pl_train_module_logit import TrainingModule\n",
    "from vulexp.ml_models.gin import GIN\n",
    "\n",
    "saved_model = TrainingModule.load_from_checkpoint(model=GIN, map_location=device,\n",
    "                                                  checkpoint_path=\"weights/Reveal-GIN-auc_pos=0.78-optimal_t=0.560-f1=0.34-epoch=04.ckpt\")\n",
    "saved_model.to(device)\n",
    "saved_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sel = 10\n",
    "foo_sample = reveal_test.get(sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7664648294448853\n"
     ]
    }
   ],
   "source": [
    "output = saved_model(foo_sample.x.to(device), foo_sample.edge_index.to(device), None)\n",
    "pred = torch.sigmoid(output).item()\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from deap import base, algorithms, creator, tools\n",
    "from torch_geometric.utils import k_hop_subgraph, get_num_hops\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "toolbox = base.Toolbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def graph_build_zero_filling(X, edge_index, node_mask: torch.Tensor):\n",
    "    \"\"\" subgraph building through masking the unselected nodes with zero features \"\"\"\n",
    "    ret_X = X * node_mask.unsqueeze(1)\n",
    "    return ret_X, edge_index\n",
    "\n",
    "def graph_build_split(X, edge_index, node_mask: torch.Tensor):\n",
    "    \"\"\" subgraph building through spliting the selected nodes from the original graph \"\"\"\n",
    "    row, col = edge_index\n",
    "    edge_mask = (node_mask[row] == 1) & (node_mask[col] == 1)\n",
    "    ret_edge_index = edge_index[:, edge_mask]\n",
    "    return X, ret_edge_index\n",
    "\n",
    "def get_graph_build_func(build_method):\n",
    "    if build_method.lower() == 'zero_filling':\n",
    "        return graph_build_zero_filling\n",
    "    elif build_method.lower() == 'split':\n",
    "        return graph_build_split\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "def gnn_score(coalition: list, data: Data, gnn_model: Callable,\n",
    "              subgraph_building_method='zero_filling') -> torch.Tensor:\n",
    "    \"\"\" the value of subgraph with selected nodes \"\"\"\n",
    "    num_nodes = data.num_nodes\n",
    "    subgraph_build_func = get_graph_build_func(subgraph_building_method)\n",
    "    mask = torch.zeros(num_nodes).type(torch.float32).to(data.x.device)\n",
    "    mask[coalition] = 1.0\n",
    "    ret_x, ret_edge_index = subgraph_build_func(data.x, data.edge_index, mask)\n",
    "    mask_data = Data(x=ret_x, edge_index=ret_edge_index)\n",
    "    mask_data = Batch.from_data_list([mask_data])\n",
    "    score = gnn_model(mask_data)\n",
    "    # get the score of predicted class for graph or specific node idx\n",
    "    return score.item()\n",
    "\n",
    "def get_fitness_func(score_method, gnn_model, subgraph_building_method='zero_filling'):\n",
    "    \"\"\" Function factory to generate a method measure how quality of a individual\n",
    "    Args:\n",
    "        score_method: method to use\n",
    "        gnn_model:  a blackbox algorithm\n",
    "        subgraph_building_method: way to construct a suggraph\n",
    "    \"\"\"\n",
    "    if score_method.lower() == 'gnn_score':\n",
    "        return partial(gnn_score,\n",
    "                       gnn_model=gnn_model,\n",
    "                       subgraph_building_method=subgraph_building_method)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "def wrap_classifier(data):\n",
    "    \"\"\" Wraper for any classification method\n",
    "    \"\"\"\n",
    "    out = saved_model(x=data.x.to(device), edge_index=data.edge_index.to(device), batch=None)\n",
    "    prod = torch.sigmoid(out)\n",
    "    return prod\n",
    "\n",
    "def evalSubGraph(individual: list, origin_graph: Data, K=6) -> float:\n",
    "    \"\"\" A value of a subgraph is scored by how close gnn output from it and original graph.\n",
    "        The final value takk size of subgraph to consideration.\n",
    "        We are going to minize this function\n",
    "    \"\"\"\n",
    "    coalition = [i for i,v in enumerate(individual) if v==1]\n",
    "    fitness_func = get_fitness_func('gnn_score', wrap_classifier)\n",
    "    fitness_value = fitness_func(coalition=coalition, data=origin_graph)\n",
    "    origin_fitness_value = wrap_classifier(origin_graph)\n",
    "    return abs(fitness_value - origin_fitness_value.item()) + (abs(len(coalition)-K)/origin_graph.num_nodes),\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Individual(object):\n",
    "    def __init__(self, nodes):\n",
    "        if type(nodes) is list:\n",
    "            self.nodes = nodes\n",
    "        else:\n",
    "            self.nodes = [i for i in nodes]\n",
    "\n",
    "    def __repr__(self):\n",
    "        coalition = [str(i) for i,v in enumerate(self.nodes) if v==1]\n",
    "        return ' '.join(coalition)\n",
    "\n",
    "    def __get__(self, instance, owner):\n",
    "        return self.nodes\n",
    "\n",
    "    def __set__(self, instance, value):\n",
    "        self.nodes = value\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.nodes[item]\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        self.nodes[key] = value\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.nodes)\n",
    "    \n",
    "    def get_nodes(self):\n",
    "        coalition = [i for i,v in enumerate(self.nodes) if v==1]\n",
    "        return coalition\n",
    "\n",
    "creator.create(\"Individual\", Individual, fitness=creator.FitnessMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feasible(individual):\n",
    "    \"\"\"Feasibility function for the individual. Returns True if feasible False\n",
    "    otherwise.\"\"\"\n",
    "    origin_graph=foo_sample  # todo\n",
    "    G = to_networkx(origin_graph, to_undirected=origin_graph.is_directed())\n",
    "    sub_graph = G.subgraph(individual.get_nodes())\n",
    "    if origin_graph.is_directed():\n",
    "        components = [i for i in nx.weakly_connected_components(sub_graph)]\n",
    "    else:\n",
    "        sub_graph = sub_graph.to_undirected()\n",
    "        components = [i for i in nx.connected_components(sub_graph)]\n",
    "    if len(components) == 1:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, \n",
    "    toolbox.attr_bool, foo_sample.num_nodes)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", evalSubGraph, origin_graph=foo_sample)\n",
    "toolbox.decorate(\"evaluate\", tools.DeltaPenalty(feasible, 10.0))\n",
    "toolbox.register(\"mate\", tools.cxPartialyMatched)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg         \tmin         \tmax  \n",
      "0  \t200   \t[9.38155917]\t[0.29557101]\t[10.]\n",
      "1  \t32    \t[5.23067462]\t[0.41690003]\t[10.]\n",
      "2  \t37    \t[0.41452285]\t[0.39853689]\t[0.44279083]\n",
      "3  \t35    \t[0.39292258]\t[0.37046534]\t[0.39853689]\n",
      "4  \t31    \t[0.36021106]\t[0.34513597]\t[0.37264044]\n",
      "5  \t37    \t[0.34000339]\t[0.32489343]\t[0.34982667]\n",
      "6  \t41    \t[0.30564956]\t[0.27890405]\t[0.34513597]\n",
      "7  \t39    \t[0.27871016]\t[0.27791116]\t[0.27890405]\n",
      "8  \t33    \t[0.27577618]\t[0.25537974]\t[0.27890399]\n",
      "9  \t36    \t[0.26209474]\t[0.2551576] \t[0.27791116]\n",
      "10 \t33    \t[0.25529089]\t[0.2551576] \t[0.25537974]\n",
      "11 \t33    \t[0.24914505]\t[0.23541591]\t[0.2551576] \n",
      "12 \t30    \t[0.232525]  \t[0.21127779]\t[0.23541591]\n",
      "13 \t33    \t[0.22279349]\t[0.21102358]\t[0.23541591]\n",
      "14 \t30    \t[0.211049]  \t[0.21102358]\t[0.21127779]\n",
      "15 \t34    \t[0.20721534]\t[0.19198237]\t[0.21102358]\n",
      "16 \t38    \t[0.20150297]\t[0.19198237]\t[0.21102358]\n",
      "17 \t32    \t[0.19154476]\t[0.18760624]\t[0.19198237]\n",
      "18 \t31    \t[0.19110715]\t[0.18760624]\t[0.19198237]\n",
      "19 \t36    \t[0.18804385]\t[0.18760624]\t[0.19198237]\n",
      "20 \t31    \t[0.18760624]\t[0.18760624]\t[0.18760624]\n",
      "21 \t34    \t[0.18257161]\t[0.16243308]\t[0.18760624]\n",
      "22 \t30    \t[0.17250235]\t[0.16243308]\t[0.18760624]\n",
      "23 \t38    \t[0.16243308]\t[0.16243308]\t[0.16243308]\n",
      "24 \t39    \t[0.156258]  \t[0.13155768]\t[0.16243308]\n",
      "25 \t30    \t[0.14390784]\t[0.13155768]\t[0.16243308]\n",
      "26 \t38    \t[0.12856533]\t[0.1215832] \t[0.13155768]\n",
      "27 \t30    \t[0.1215832] \t[0.1215832] \t[0.1215832] \n",
      "28 \t38    \t[0.1215832] \t[0.1215832] \t[0.1215832] \n",
      "29 \t37    \t[0.1215832] \t[0.1215832] \t[0.1215832] \n",
      "30 \t36    \t[0.1215832] \t[0.1215832] \t[0.1215832] \n",
      "31 \t40    \t[0.1215832] \t[0.1215832] \t[0.1215832] \n",
      "32 \t38    \t[0.11875987]\t[0.09334994]\t[0.1215832] \n",
      "33 \t39    \t[0.10181992]\t[0.09334994]\t[0.1215832] \n",
      "34 \t34    \t[0.0909104] \t[0.06895451]\t[0.09334994]\n",
      "35 \t36    \t[0.07871269]\t[0.06895451]\t[0.09334994]\n",
      "36 \t35    \t[0.06895451]\t[0.06895451]\t[0.06895451]\n",
      "37 \t35    \t[0.06895451]\t[0.06895451]\t[0.06895451]\n",
      "38 \t38    \t[0.06895451]\t[0.06895451]\t[0.06895451]\n",
      "39 \t38    \t[0.06895451]\t[0.06895451]\t[0.06895451]\n",
      "40 \t35    \t[0.06895451]\t[0.06895451]\t[0.06895451]\n",
      "41 \t31    \t[0.06895451]\t[0.06895451]\t[0.06895451]\n",
      "42 \t32    \t[0.06895451]\t[0.06895451]\t[0.06895451]\n",
      "43 \t35    \t[0.06895451]\t[0.06895451]\t[0.06895451]\n",
      "44 \t32    \t[0.0609338] \t[0.02885094]\t[0.06895451]\n",
      "45 \t39    \t[0.04890273]\t[0.02885094]\t[0.06895451]\n",
      "46 \t30    \t[0.03286129]\t[0.02885094]\t[0.06895451]\n",
      "47 \t37    \t[0.02885094]\t[0.02885094]\t[0.02885094]\n",
      "48 \t33    \t[0.02885094]\t[0.02885094]\t[0.02885094]\n",
      "49 \t41    \t[0.02885094]\t[0.02885094]\t[0.02885094]\n",
      "50 \t39    \t[0.02885094]\t[0.02885094]\t[0.02885094]\n",
      "51 \t33    \t[0.02885094]\t[0.02885094]\t[0.02885094]\n",
      "52 \t35    \t[0.02883105]\t[0.02875152]\t[0.02885094]\n",
      "53 \t35    \t[0.02880123]\t[0.02875152]\t[0.02885094]\n",
      "54 \t30    \t[0.02875152]\t[0.02875152]\t[0.02875152]\n",
      "55 \t29    \t[0.02875152]\t[0.02875152]\t[0.02875152]\n",
      "56 \t29    \t[0.02875152]\t[0.02875152]\t[0.02875152]\n",
      "57 \t41    \t[0.02875152]\t[0.02875152]\t[0.02875152]\n",
      "58 \t41    \t[0.02526664]\t[0.01121575]\t[0.02875152]\n",
      "59 \t36    \t[0.01998363]\t[0.01121575]\t[0.02875152]\n",
      "60 \t35    \t[0.01296932]\t[0.01121575]\t[0.02875152]\n",
      "61 \t33    \t[0.01032249]\t[0.00228316]\t[0.01121575]\n",
      "62 \t37    \t[0.01121575]\t[0.01121575]\t[0.01121575]\n",
      "63 \t34    \t[0.01121575]\t[0.01121575]\t[0.01121575]\n",
      "64 \t33    \t[0.01121575]\t[0.01121575]\t[0.01121575]\n",
      "65 \t30    \t[0.01121575]\t[0.01121575]\t[0.01121575]\n",
      "66 \t30    \t[0.01121575]\t[0.01121575]\t[0.01121575]\n",
      "67 \t37    \t[0.01121575]\t[0.01121575]\t[0.01121575]\n",
      "68 \t39    \t[0.01121575]\t[0.01121575]\t[0.01121575]\n",
      "69 \t37    \t[0.01121575]\t[0.01121575]\t[0.01121575]\n",
      "70 \t29    \t[0.01121575]\t[0.01121575]\t[0.01121575]\n",
      "71 \t28    \t[0.01121575]\t[0.01121575]\t[0.01121575]\n",
      "72 \t37    \t[0.01065348]\t[0.00559306]\t[0.01121575]\n",
      "73 \t43    \t[0.0084044] \t[0.00559306]\t[0.01121575]\n",
      "74 \t35    \t[0.00559306]\t[0.00559306]\t[0.00559306]\n",
      "75 \t32    \t[0.00526207]\t[0.00228316]\t[0.00559306]\n",
      "76 \t38    \t[0.00460009]\t[0.00228316]\t[0.00559306]\n",
      "77 \t32    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "78 \t36    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "79 \t38    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "80 \t27    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "81 \t36    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "82 \t33    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "83 \t37    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "84 \t32    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "85 \t34    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "86 \t34    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "87 \t35    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "88 \t33    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "89 \t37    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "90 \t34    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "91 \t33    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "92 \t34    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "93 \t34    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "94 \t28    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "95 \t30    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "96 \t39    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "97 \t34    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "98 \t34    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 15:03:37 | GASub | hof: 0.002 << 14 15 33 36 37 38\n",
      "2022-08-01 15:03:37 | GASub | hof: 0.002 << 14 15 33 36 37 38\n",
      "2022-08-01 15:03:37 | GASub | hof: 0.002 << 14 15 33 36 37 38\n",
      "2022-08-01 15:03:37 | GASub | hof: 0.002 << 14 15 33 36 37 38\n",
      "2022-08-01 15:03:37 | GASub | hof: 0.002 << 14 15 33 36 37 38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 \t37    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n",
      "100\t35    \t[0.00228316]\t[0.00228316]\t[0.00228316]\n"
     ]
    }
   ],
   "source": [
    "CXPB = args.CXPB\n",
    "MUTPB = args.MUTPB\n",
    "\n",
    "logger = setup_logger()\n",
    "\n",
    "# keep track of the best individuals\n",
    "hof = tools.HallOfFame(5)\n",
    "history = tools.History()\n",
    "\n",
    "# setting the statistics (displayed for each generation)\n",
    "stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
    "stats.register('avg', np.mean, axis=0)\n",
    "stats.register('min', np.min, axis=0)\n",
    "stats.register('max', np.max, axis=0)\n",
    "\n",
    "pop = toolbox.population(200)\n",
    "history.update(pop)\n",
    "\n",
    "try:\n",
    "    final_population, logbook = algorithms.eaMuPlusLambda(\n",
    "        pop, toolbox,\n",
    "        mu=10, lambda_=50, cxpb=CXPB, mutpb=MUTPB,\n",
    "        ngen=100, stats=stats, halloffame=hof, verbose=True)\n",
    "except (Exception, KeyboardInterrupt) as e:\n",
    "    logging.info(e)\n",
    "    for individual in hof:\n",
    "        logger.info(\n",
    "            f'hof: {individual.fitness.values[0]:.3f} << {individual}')\n",
    "\n",
    "for individual in hof:\n",
    "    logger.info(\n",
    "        f'hof: {individual.fitness.values[0]:.3f} << {individual}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c654daa9bf41bf94f45c1eaea445ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0, 21, 22, 23, 30, 31)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vulexp.explanation.subgraphx import SubgraphX\n",
    "\n",
    "reveal_subgraphx = SubgraphX(model=saved_model, min_nodes=6)\n",
    "subgraph = reveal_subgraphx.explain(x=foo_sample.x.to(device), edge_index=foo_sample.edge_index.to(device), max_nodes=6)\n",
    "\n",
    "subgraph.coalition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remove_nodes(raw_graph: nx.Graph, graph_label, node_set: Optional[Set[int]]):\n",
    "    from vulexp.data_models.helpers import from_networkx, convert_single_graph\n",
    "    cp_graph = raw_graph.copy()\n",
    "    cp_graph.remove_nodes_from(node_set)\n",
    "    new_graph = from_networkx(convert_single_graph(cp_graph), group_node_attrs=['feat'])\n",
    "    new_graph.y = torch.LongTensor([graph_label])\n",
    "    new_graph.x = new_graph.x.float()\n",
    "    return new_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ga_mask = torch.zeros(foo_sample.num_nodes).type(torch.float32).to(foo_sample.x.device)\n",
    "ga_mask[hof[-1].get_nodes()] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sub_mask = torch.zeros(foo_sample.num_nodes).type(torch.float32).to(foo_sample.x.device)\n",
    "sub_mask[list(subgraph.coalition)] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ga_result = graph_build_split(foo_sample.x, foo_sample.edge_index, ga_mask)\n",
    "sub_result = graph_build_split(foo_sample.x, foo_sample.edge_index, sub_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7301464676856995\n"
     ]
    }
   ],
   "source": [
    "output = saved_model(ga_result[0].to(device), ga_result[1].to(device), None)\n",
    "pred = torch.sigmoid(output).item()\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.577610194683075\n"
     ]
    }
   ],
   "source": [
    "output = saved_model(sub_result[0].to(device), sub_result[1].to(device), None)\n",
    "pred = torch.sigmoid(output).item()\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ga_subgraph')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ffcbbd9b6f323d2d2a0d60c1ee37af36d4102b89e9c5f16911bd71b97bdbbb2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}